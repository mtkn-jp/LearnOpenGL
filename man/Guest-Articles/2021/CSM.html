    <div id="content">
    <h1 id="content-title">CSM</h1>
<h1 id="content-url" style='display:none;'>Guest-Articles/2021/CSM</h1>
<p>
		<a href="https://learnopengl.com/Advanced-Lighting/Shadows/Shadow-Mapping" target="_blank">Shadow mapping</a> as described on LearnOpenGL is a powerful, and relatively simple technique. However, if implemented as-is from the above referred tutorial, the avid OpenGL student will notice a few shortcomings.
	</p>
	<ul>
		<li>The shadow map is always created around the origin, and not on the area the camera is actually looking at. It would be best of course if we could shadow map the whole scene, with sufficient resolution, but on current hardware this is not feasible. In reality we want the shadow maps to be created on objects that are in view, saving our precious GPU memory for things that matter. </li>
		<li>The shadow map orthographic projection matrix is not properly fitted onto the view frustum. To achieve the best possible resolution for our shadow maps, the ortho matrix needs to be as tightly fit to the camera frustum as possible, because again: if it’s larger that means that less detail is spent on the objects that are actually visible.</li>
		<li>The shadow maps (even with advanced PCF functions) are blurry if we want the shadow rendering distance to be large, as we would in a game with a first-person camera. We can increase the resolution of the shadow maps to mitigate this, but GPU memory is a resource we should be conservative of.</li>
	</ul>
	<p>
		Cascaded shadow mapping is a direct answer to the third point, however while implementing it we will solve the first two points, too. The core insight in cascaded shadow mapping is, that we don’t need the same amount of shadow detail for things that are far from us. We want crisp shadows for stuff that’s near to the near plane, and we are absolutely fine with blurriness for objects that are hundreds of units away: it’s not going to be noticeable at all. How can we achieve this? The answer is beautiful in its simplicity: just render different shadow maps for things that are close and for those that are far away, and sample from them according to the depth of the fragment in the fragment shader. The high-level algorithm is as follows:
	</p>
	<ul>
		<li>Divide our ordinary view frustum into n subfrusta, where the far plane of the <code>i</code>-th frustum is the near plane of the <code>(i+1)</code>-th frustum</li>
		<li>Compute the tightly fitting ortho matrix for each frustum</li>
		<li>For each frustum render a shadow map as if seen from our directional light</li>
		<li>Send all shadow maps to our fragment shader</li>
		<li>Render the scene, and according to the fragment’s depth value sample from the correct shadow map</li>
	</ul>
	<p>
		Sounds simple right? Well, it is, but as it often is when it comes to our friend OpenGL: the devil is in the details.
	</p>
	<img src="/img/guest/2021/CSM/cs_go.png" width="800px">
	<p>
		In the above image we can see the edges of shadow cascades in Counter-Strike: Global Offensive. The image was captured on low graphics settings.
	</p>
      
	<h2>World coordinates of the view frustum</h2>
	<p>
		Before getting our hands dirty with shadows, we need to tackle a more abstract problem: making our projection matrix fit nicely onto a generic frustum. To be able to do this, we need to know the world space coordinates of the frustum in question. While this might sound daunting at first, we already have all the tools necessary in our repertoire.  If we think back on the excellent <a href="https://learnopengl.com/Getting-started/Coordinate-Systems" target="_blank"> coordinate systems</a> tutorial, the beheaded pyramid of the frustum only looks that way in world coordinates, and our view and projection matrices do the job of transforming this unusual shape into the NDC cube. And we know the coordinates of the corners of the NDC cube: the coordinates are in the range <code>[-1,1]</code>  on the three axes. Because matrix multiplication is a reversible process, we can apply the inverse of the view and projection matrices on the corner points of the NDC cube to get the frustum corners in world space.
	</p>
	<math>
		$$v_{NDC} = M_{proj} M_{view} v_{world}$$
		$$v_{world} = (M_{proj} M_{view})^{-1} v_{NDC}$$
	</math>

<pre><code>
std::vector&lt;glm::vec4&gt; getFrustumCornersWorldSpace(const glm::mat4& proj, const glm::mat4& view)
{
    const auto inv = glm::inverse(proj * view);
    
    std::vector&lt;glm::vec4> frustumCorners;
    for (unsigned int x = 0; x &lt; 2; ++x)
    {
        for (unsigned int y = 0; y &lt; 2; ++y)
        {
            for (unsigned int z = 0; z &lt; 2; ++z)
            {
                const glm::vec4 pt = 
                    inv * glm::vec4(
                        2.0f * x - 1.0f,
                        2.0f * y - 1.0f,
                        2.0f * z - 1.0f,
                        1.0f);
                frustumCorners.push_back(pt / pt.w);
            }
        }
    }
    
    return frustumCorners;
}
</code></pre>
  
	<p>
		The projection matrix described here is a perspective matrix, using the camera’s aspect ratio and fov, and using the near and far plane of the current frustum being analyzed. The view matrix is the view matrix of our camera.
	</p>
      
<pre><code>
const auto proj = <function id='58'>glm::perspective</function>(
    <function id='63'>glm::radians</function>(camera.Zoom),
    (float)SCR_WIDTH / (float)SCR_HEIGHT,
    nearPlane,
    farPlane
);
</code></pre>
      
	<img src="/img/guest/2021/CSM/frustum_fitting.png">
	<br>
      
	<h2>The light view-projection matrix</h2>
	<p>
		This matrix - as in ordinary shadow mapping – is the product of the view and projection matrix that transforms the scene as if it were seen by the light. Calculating the view matrix is simple, we know the direction our light is coming from, and we know a point in world space that it definitely is looking at: the center of the frustum. The position of the frustum center can be obtained by averaging the coordinates of the frustum corners. (This is so because averaging the coordinates of the near and far plane gives us the center of those rectangles, and taking the midpoint of these two points gives us the center of the frustum.)
	</p>
	<pre><code>
glm::vec3 center = glm::vec3(0, 0, 0);
for (const auto& v : corners)
{
    center += glm::vec3(v);
}
center /= corners.size();
    
const auto lightView = <function id='62'>glm::lookAt</function>(
    center + lightDir,
    center,
    glm::vec3(0.0f, 1.0f, 0.0f)
);
    </code></pre>
	<p>
		The projection matrix is bit more complex. Because the light in question is a directional light, the matrix needs to be an orthographic projection matrix, this much is clear. To understand how we determine the left, right, top etc. parameters of the matrix imagine the scene you are drawing from the perspective of the light. From this viewpoint the shadow map we are trying to render is going to be an axis aligned rectangle, and this rectangle – as we established before – needs to fit on the frustum tightly. So we need to obtain the coordinates of the frustum in this space, and take the maximum and minimum of the coordinates along the coordinate axes. While this might sound daunting at first, this perspective is exactly what our light view matrix transformation gives us. We need to transform the frustum corner points in the light view space, and find the maximum and minimum coordinates.
	</p>
      
	<pre><code>
float minX = std::numeric_limits&lt;float>::max();
float maxX = std::numeric_limits&lt;float>::min();
float minY = std::numeric_limits&lt;float>::max();
float maxY = std::numeric_limits&lt;float>::min();
float minZ = std::numeric_limits&lt;float>::max();
float maxZ = std::numeric_limits&lt;float>::min();
for (const auto& v : corners)
{
    const auto trf = lightView * v;
    minX = std::min(minX, trf.x);
    maxX = std::max(maxX, trf.x);
    minY = std::min(minY, trf.y);
    maxY = std::max(maxY, trf.y);
    minZ = std::min(minZ, trf.z);
    maxZ = std::max(maxZ, trf.z);
}
	</code></pre>
      
	<p>
		We are going to create our projection matrix from the product of two matrices. First, we are going to create an ortho projection matrix, with the left, right, top, bottom parameters set to <code>-1</code> or <code>1</code>, and the z values set to <var>minZ</var> and <var>maxZ</var>. This creates a 3D rectangle sitting on the origin with width and height of <code>2</code>, and depth of (<var>maxZ</var> – <var>minZ</var>). In the code we increase the amount of space covered by <var>minZ</var> and <var>maxZ</var> by multiplying or dividing them with a <var>zMult</var>. This is because we want to include geometry which is behind or in front of our frustum in camera space. Think about it: not only geometry which is in the frustum can cast shadows on a surface in the frustum!
	</p>
      
<pre><code>
// Tune this parameter according to the scene
constexpr float zMult = 10.0f;
if (minZ &lt; 0)
{
    minZ *= zMult;
}
else
{
    minZ /= zMult;
}
if (maxZ &lt; 0)
{
    maxZ /= zMult;
}
else
{
    maxZ *= zMult;
}
   
const glm::mat4 lpMatrix = <function id='59'>glm::ortho</function>(-1.0f, 1.0f, -1.0f, 1.0f, minZ, maxZ);
</code></pre>
	<p>
		The other part of our projection matrix is going to be a crop matrix, which moves the rectangle onto the frustum in light view space. Starting from a unit matrix, we need to set the x and y scaling components, and the x and y offset components of the matrix. 
	</p>
      
	<math>
		$$S_x = {2 \over M_x - m_x}$$
		$$S_y = {2 \over M_y - m_y}$$
		$$O_x = -0.5(M_x + m_x)S_x$$
		$$O_y = -0.5(M_y + m_y)S_y$$
		$$C = \begin{bmatrix}S_x & 0 & 0 & O_x \\0 & S_y & 0 & O_y \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1\end{bmatrix}$$
	</math>
	
	<p>
		Let’s look at S<sub>x</sub>. It needs to shrink down the frustum bounding rectangle to a unit size, this is achieved by dividing by the width of the rectangle (M<sub>x</sub> – m<sub>x</sub>). However, we need to scale by <code>2</code>, because our 3D rectangle sitting on the origin has a width of <code>2</code>. S<sub>y</sub> is analogous to this.
	</p>
	<img src="/img/guest/2021/CSM/frustum_cropping.png" width="800px">
	<p>
		For the x offset, we need to multiply by the negative halfway point between M<sub>x</sub> and m<sub>x</sub>, and scale by S<sub>x</sub>. And the y offset is analogous.
	</p>
	
<pre><code>
const float scaleX = 2.0f / (maxX - minX);
const float scaleY = 2.0f / (maxY - minY);
const float offsetX = -0.5f * (minX + maxX) * scaleX;
const float offsetY = -0.5f * (minY + maxY) * scaleY;
    
glm::mat4 cropMatrix(1.0f);
cropMatrix[0][0] = scaleX;
cropMatrix[1][1] = scaleY;
cropMatrix[3][0] = offsetX;
cropMatrix[3][1] = offsetY;
    
return cropMatrix * lpMatrix * lightView;
</code></pre>
	
	<p>
		Multiplying the view, projection and crop matrices together, we get the view-projection matrix of the light for the given frustum. We need to do this procedure for every frustum in our cascade.
	</p>
      
	<h2>2D array textures</h2>
	<p>
		While we let our stomachs digest what we learned about frustum fitting we should figure out how to store our shadow maps. In principle there is no limit on how many cascades we can do, so hardcoding an arbitrary value doesn’t seem like a wise idea. Also, it quickly becomes tiresome typing out and binding sampler2Ds for our shaders. OpenGL has a good solution to this problem in the form of <def>2D array textures</def>. This object is an array of textures, which have the same dimensions. To use them in shaders declare them like this:
	</p>
      
<pre><code>
uniform sampler2DArray shadowMap;
</code></pre>
      
	<p>
		To sample from them we can use the regular texture function with a vec3 parameter for texture coordinates, the third dimension specifying which layer to sample from, starting from <code>0</code>.
	</p>
      
<pre><code>
texture(depthMap, vec3(TexCoords, currentLayer))
</code></pre>
      
	<p>
		Creating our array texture is slightly different than creating a regular old texture2D. Instead of <function id='52'>glTexImage2D</function> we use glTexImage3D to allocate memory, and when binding the texture to the framebuffer we use glFramebufferTexture instead of <function id='81'>glFramebufferTexture2D</function>. The parameters of these functions are somewhat self-explanatory if we know the old versions. When calling the OpenGL functions, we need to pass <var>GL_TEXTURE_2D_ARRAY</var> instead of <var>GL_TEXTURE_2D</var> as the target, to tell OpenGL what kind of texture we are dealing with.
	</p>
	
<pre><code>
<function id='76'>glGenFramebuffers</function>(1, &lightFBO);
    
<function id='50'>glGenTextures</function>(1, &lightDepthMaps);
<function id='48'>glBindTexture</function>(GL_TEXTURE_2D_ARRAY, lightDepthMaps);
glTexImage3D(
    GL_TEXTURE_2D_ARRAY,
    0,
    GL_DEPTH_COMPONENT32F,
    depthMapResolution,
    depthMapResolution,
    int(shadowCascadeLevels.size()) + 1,
    0,
    GL_DEPTH_COMPONENT,
    GL_FLOAT,
    nullptr);
    
<function id='15'>glTexParameter</function>i(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
<function id='15'>glTexParameter</function>i(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
<function id='15'>glTexParameter</function>i(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER);
<function id='15'>glTexParameter</function>i(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER);
    
constexpr float bordercolor[] = { 1.0f, 1.0f, 1.0f, 1.0f };
<function id='15'>glTexParameter</function>fv(GL_TEXTURE_2D_ARRAY, GL_TEXTURE_BORDER_COLOR, bordercolor);
    
<function id='77'>glBindFramebuffer</function>(GL_FRAMEBUFFER, lightFBO);
glFramebufferTexture(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, lightDepthMaps, 0);
glDrawBuffer(GL_NONE);
glReadBuffer(GL_NONE);
    
int status = <function id='79'>glCheckFramebufferStatus</function>(GL_FRAMEBUFFER);
if (status != GL_FRAMEBUFFER_COMPLETE)
{
    std::cout &lt;&lt; "ERROR::FRAMEBUFFER:: Framebuffer is not complete!";
    throw 0;
}
    
<function id='77'>glBindFramebuffer</function>(GL_FRAMEBUFFER, 0);
</code></pre>
      
	<p>
		Take care when binding this texture to a sampler. Again: we need to use <var>GL_TEXTURE_2D_ARRAY</var> as the target parameter.
	</p>
      
<pre><code>
<function id='49'>glActiveTexture</function>(GL_TEXTURE1);
<function id='48'>glBindTexture</function>(GL_TEXTURE_2D_ARRAY, lightDepthMaps);
</code></pre>
	
	<p>
		So far so good, now we know the semantics of using a texture array. It all seems straightforward, but OpenGL has one more curveball to throw at us: we can’t render into this texture the ordinary way, we need to do something called <def>layered rendering</def>. This process is very similar to what we did with <a href="https://learnopengl.com/Advanced-Lighting/Shadows/Point-Shadows" target="_blank">cubemaps and pointlights</a> , we coax the <a href="https://learnopengl.com/Advanced-OpenGL/Geometry-Shader" target="_blank">geometry shader</a> into generating multiple layers of geometry for us at the same time. If we recall our depthmap shader is very simple: transform the vertices to light space in the vertex stage, and let the hardware do the rest with an empty fragment shader. In our new depthmap shader we are going to only do the world space transformation in the vertex shader.
	</p>
      
<pre><code>
#version 460 core
layout (location = 0) in vec3 aPos;
    
uniform mat4 model;
    
void main()
{
    gl_Position = model * vec4(aPos, 1.0);
}
</code></pre>
  
	<p>
	The newly inserted geometry shader will look something like this:
	</p>
      
<pre><code>
#version 460 core
    
layout(triangles, invocations = 5) in;
layout(triangle_strip, max_vertices = 3) out;
    
layout (std140, binding = 0) uniform LightSpaceMatrices
{
    mat4 lightSpaceMatrices[16];
};
    
void main()
{          
    for (int i = 0; i &lt; 3; ++i)
    {
        gl_Position = 
            lightSpaceMatrices[gl_InvocationID] * gl_in[i].gl_Position;
        gl_Layer = gl_InvocationID;
        EmitVertex();
    }
    EndPrimitive();
}  
</code></pre>
      
	<p>
		The input declaration has a new member, specifying the <def>invocation count</def>. This number means, that this shader will be instanced, these instances running in parallel, and we can refer the current instance by the inbuilt variable <var>gl_InvocationID</var>. We will use this number in the shader code to reference which layer of the array texture we are rendering to, and which shadow matrix we are going to use to do the light space transform. We are iterating over all triangles, and setting <var>gl_Layer</var> and <var>gl_Position</var> accordingly. 
	</p>
      
	<note>
		I strongly suggest modifying your Shader class in your engine to enable the possibility of inserting variables into the shader code before shader compilation, so that you can make the <i>invocations</i> parameter dynamic. This way if you modify the number of cascades in the C++ code you dont have to modify the shader itself, removing one cog from the complex machine that is your engine. I didn't include this in the tutorial for the sake of simplicity.
	</note>
      
	<p>
		The fragment shader remains the same empty, passthrough shader.
	</p>
      
<pre><code>
#version 460 core
    
void main()
{             
}
</code></pre>
      
	<p>
		Our draw call invoking the shader looks something like this:
	</p>
      
<pre><code>
simpleDepthShader.use();
    
<function id='77'>glBindFramebuffer</function>(GL_FRAMEBUFFER, lightFBO);
glFramebufferTexture(GL_FRAMEBUFFER, GL_TEXTURE_2D_ARRAY, lightDepthMaps, 0);
<function id='22'>glViewport</function>(0, 0, depthMapResolution, depthMapResolution);
<function id='10'>glClear</function>(GL_DEPTH_BUFFER_BIT);
<function id='74'>glCullFace</function>(GL_FRONT);  // peter panning
renderScene(simpleDepthShader);
<function id='74'>glCullFace</function>(GL_BACK);
<function id='77'>glBindFramebuffer</function>(GL_FRAMEBUFFER, 0);
</code></pre>
      
	<img src="/img/guest/2021/CSM/cascades.png" width="800px">

	<h2>Scene rendering</h2>
	<p>
		Now the only thing remaining is doing the actual shadow rendering. In our ordinary phong/deferred fragment shader where we calculate whether the current fragment is occluded or not, we need to insert some logic to decide which light space matrix to use, and which texture to sample from.
	</p>
      
<pre><code>
// select cascade layer
vec4 fragPosViewSpace = view * vec4(fragPosWorldSpace, 1.0);
float depthValue = abs(fragPosViewSpace.z);
    
int layer = -1;
for (int i = 0; i &lt; cascadeCount; ++i)
{
    if (depthValue &lt; cascadePlaneDistances[i])
    {
        layer = i;
        break;
    }
}
if (layer == -1)
{
    layer = cascadeCount;
}
    
vec4 fragPosLightSpace = lightSpaceMatrices[layer] * vec4(fragPosWorldSpace, 1.0);
</code></pre>
      
	<p>
		If you remember to prevent shadow acne we applied a depth bias to our image. We need to do the same here, but keep in mind that we are dealing with multiple shadow maps, and on each of them the pixels cover a widely different amount of space, and a unit increase in pixel value means  different depth increase in all of them. Because of this we need to apply a different bias depending on which shadow map we sample from. In my experience scaling the bias inversely proportionally with the far plane works nicely.
	</p>
      
<pre><code>
// perform perspective divide
vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
// transform to [0,1] range
projCoords = projCoords * 0.5 + 0.5;
    
// get depth of current fragment from light's perspective
float currentDepth = projCoords.z;
if (currentDepth  &gt; 1.0)
{
    return 0.0;
}
// calculate bias (based on depth map resolution and slope)
vec3 normal = normalize(fs_in.Normal);
float bias = max(0.05 * (1.0 - dot(normal, lightDir)), 0.005);
if (layer == cascadeCount)
{
    bias *= 1 / (farPlane * 0.5f);
}
else
{
    bias *= 1 / (cascadePlaneDistances[layer] * 0.5f);
}
</code></pre>
      
	<note>
		Please note that there are different strategies for applying bias when dealing with shadow maps. I will link to a few sources detailing these in the citations section.
	</note>
      
	<p>
		The rest of the function is the same as before, the only difference is that we are sampling from a 2D array texture, hence we need to add a third parameter to the <fun>texture</fun> and the <fun>textureSize</fun> functions.
	</p>
      
<pre><code>
// PCF
float shadow = 0.0;
vec2 texelSize = 1.0 / vec2(textureSize(shadowMap, 0));
for(int x = -1; x &lt;= 1; ++x)
{
    for(int y = -1; y &lt;= 1; ++y)
    {
        float pcfDepth = texture(
                    shadowMap,
                    vec3(projCoords.xy + vec2(x, y) * texelSize,
                    layer)
                    ).r; 
        shadow += (currentDepth - bias) > pcfDepth ? 1.0 : 0.0;        
    }    
}
shadow /= 9.0;
    
// keep the shadow at 0.0 when outside the far_plane region of the light's frustum.
if(projCoords.z &gt; 1.0)
{
    shadow = 0.0;
}
    	
return shadow;
</code></pre>
      
	<p>
		And that's it! If we did everything correctly we should see that the renderer switches between shadow maps based on the distance. Try setting some unreasonable cascade plane distances (for example only one, which is a few units from the camera) to see if the code really does work. You should see a noticable degradation in shadow quality between the two sides of the plane. If you see moire artifacts on the screen try changing around bias parameters a bit.
	</p>
      
      <img src="/img/guest/2021/CSM/demoscene.png" width="800px">
        
        <p>
          You can find the full source code for the cascaded shadow mapping demo <a href="/code_viewer_gh.php?code=src/8.guest/2021/2.csm/shadow_mapping.cpp" target="_blank">here</a>.
        </p>

	<h2>Closing thoughts</h2>
	<p>
		In the sample project provided you can toggle depthmap visualization by pressing <kbd>F</kbd>. When in depthmap visualization mode you can press the <kbd>+</kbd> key to swap between the different layers.
	</p>
	<p>
		When browsing through the code you might wonder why is the UBO array length <code>16</code>. This is just an arbitrary choice, to me it seemed unlikely that anyone would use more than <code>16</code> shadow cascades, so this seemed like a nice number to allocate.
	</p>
      
	<h2>Additional Resources</h2>
	<ul>
		<li><a href="https://developer.download.nvidia.com/SDK/10.5/opengl/src/cascaded_shadow_maps/doc/cascaded_shadow_maps.pdf" target="_blank">NVIDIA paper on the subject:</a> incomprehensible in my opinion but has to be mentioned</li>
		<li><a href="https://www.gamedev.net/forums/topic/672664-fitting-directional-light-in-view-frustum/?page=1" target="_blank">A series of incredibly helpful and useful forum posts</a></li>
		<li><a href="https://ogldev.org/www/tutorial49/tutorial49.html" target="_blank">Another interesting tutorial from OGLDev</a></li>
		<li><a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/cascaded-shadow-maps" target="_blank">An article from Microsoft:</a> nice pictures illustrating some issues with CSM</li>
		<li><a href="https://digitalrune.github.io/DigitalRune-Documentation/html/3f4d959e-9c98-4a97-8d85-7a73c26145d7.htm" target="_blank">An article about shadow bias</a></li>
		<li><a href="http://c0de517e.blogspot.com/2011/05/shadowmap-bias-notes.html" target="_blank">Some informative drawings about shadow bias strategies</a></li>
	</ul>
	<br>
      
<author>
  <strong>Article by: </strong>Márton Árbócz<br/>
  <!--<strong>Contact: </strong><a href="mailto:eklavyagames@gmail.com" target="_blank">e-mail</a>-->
</author>       

    </div>
    
